{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import json\n",
    "\n",
    "\n",
    "## NUMPY IMPORTS\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "\n",
    "# TENSORFLOW\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "## KERAS\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout,Reshape\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.activations import relu, softmax\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  having opencv \n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "dataFolderPath = \"data2/\"\n",
    "imageFolderPath = \"data2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataFolderPath+\"driving_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### preprocessing the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_size_col,new_size_row = 64, 64\n",
    "\n",
    "def trans_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*2*.2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    #tr_y = 0\n",
    "    cols = 320\n",
    "    rows =160\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    \n",
    "    return image_tr,steer_ang\n",
    "\n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    #print(random_bright)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def add_random_shadow(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocessImage(image):\n",
    "#     image = cv2.imread(imageFolderPath+imagePath)\n",
    "#     image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    shape = image.shape\n",
    "    # note: numpy arrays are (row, col)!\n",
    "    image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]]\n",
    "    image = cv2.resize(image,(new_size_col,new_size_row),         interpolation=cv2.INTER_AREA)    \n",
    "#     image= cv2.resize(image,None,fx=.5, fy=.5, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    #image = image/255.-.5\n",
    "    return image\n",
    "\n",
    "def preprocess_image_file_train(line_data):\n",
    "    i_lrc = np.random.randint(3)\n",
    "    if (i_lrc == 0):\n",
    "        path_file = line_data['left'][0].strip()\n",
    "        shift_ang = .25\n",
    "    if (i_lrc == 1):\n",
    "        path_file = line_data['center'][0].strip()\n",
    "        shift_ang = 0.\n",
    "    if (i_lrc == 2):\n",
    "        path_file = line_data['right'][0].strip()\n",
    "        shift_ang = -.25\n",
    "    y_steer = line_data['steering'][0] + shift_ang\n",
    "    image = cv2.imread(imageFolderPath+path_file)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "#     image,y_steer,tr_x = trans_image(image,y_steer,100)\n",
    "    image = augment_brightness_camera_images(image)\n",
    "    image = preprocessImage(image)\n",
    "    image = np.array(image)\n",
    "    ind_flip = np.random.randint(2)\n",
    "    if ind_flip==0:\n",
    "        image = cv2.flip(image,1)\n",
    "        y_steer = -y_steer\n",
    "    \n",
    "    return image,y_steer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   center  \\\n",
      "0  IMG/center_2017_01_29_22_27_17_218.jpg   \n",
      "\n",
      "                                    left  \\\n",
      "0   IMG/left_2017_01_29_22_27_17_218.jpg   \n",
      "\n",
      "                                    right  steering  throttle  brake    speed  \n",
      "0   IMG/right_2017_01_29_22_27_17_218.jpg       0.0       0.0      0  0.00008  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[189, 193,  43],\n",
       "         [175, 171,  54],\n",
       "         [204, 196,  80],\n",
       "         ..., \n",
       "         [ 46,  52,  46],\n",
       "         [ 94,  88,  53],\n",
       "         [ 46,  53,  26]],\n",
       " \n",
       "        [[192, 197,  55],\n",
       "         [179, 177,  66],\n",
       "         [197, 191,  94],\n",
       "         ..., \n",
       "         [ 39,  44,  33],\n",
       "         [120, 116,  77],\n",
       "         [ 40,  47,  29]],\n",
       " \n",
       "        [[191, 196,  64],\n",
       "         [175, 177,  71],\n",
       "         [152, 149,  87],\n",
       "         ..., \n",
       "         [ 69,  72,  50],\n",
       "         [121, 118,  70],\n",
       "         [ 32,  42,  32]],\n",
       " \n",
       "        ..., \n",
       "        [[ 12,  11,   9],\n",
       "         [ 36,  35,  21],\n",
       "         [ 90,  95,  77],\n",
       "         ..., \n",
       "         [115, 117, 103],\n",
       "         [115, 117, 104],\n",
       "         [ 99, 101,  87]],\n",
       " \n",
       "        [[ 18,  18,  16],\n",
       "         [ 85,  82,  75],\n",
       "         [ 93, 106,  72],\n",
       "         ..., \n",
       "         [133, 135, 121],\n",
       "         [127, 129, 116],\n",
       "         [114, 116, 102]],\n",
       " \n",
       "        [[ 61,  57,  52],\n",
       "         [101,  79, 101],\n",
       "         [154, 142,  85],\n",
       "         ..., \n",
       "         [106, 107,  94],\n",
       "         [117, 118, 105],\n",
       "         [122, 123, 110]]], dtype=uint8), -0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.iloc[:,0]\n",
    "print(df.iloc[[0]])\n",
    "preprocess_image_file_train(df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #  getting the xdata in the table set\n",
    "\n",
    "# x_data=np.array([preprocessImage(imagePath) for imagePath in df.iloc[:,0]])\n",
    "# print(np.shape(x_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(x_data[758])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5491,)\n"
     ]
    }
   ],
   "source": [
    "## getting the ydata\n",
    "# \"{0:.2f}\".format(round(data,2))\n",
    "y_data = np.array([ data for data in df.iloc[:,3] ])\n",
    "print(np.shape(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # TODO: One Hot encode the labels to the variable y_one_hot\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# label_binarizer = LabelBinarizer()\n",
    "# y_one_hot = label_binarizer.fit_transform(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(np.shape(newXData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # here i want to visualize the data that is used\n",
    "# sampleImage = imread(df.get_value(29,0))\n",
    "# print (np.shape(sampleImage))\n",
    "# # plt.axis(\"off\")\n",
    "# plt.imshow(sampleImage)\n",
    "# # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# label_binarizer = LabelBinarizer()\n",
    "# y_one_hot = label_binarizer.fit_transform(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is nvidia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TODO: Re-construct the network and add a pooling layer after the convolutional layer.\n",
    "# model = Sequential()\n",
    "# # model.add(Convolution2D(32, 2, 2, input_shape=(32, 32, 3)))\n",
    "# # model.add(Reshape(input_shape + (1, ), input_shape=input_shape))\n",
    "\n",
    "# # model.add(Convolution2D(32, 3,3, input_shape=(160, 320, 3)))\n",
    "# model.add(Convolution2D(24, 5, 5,input_shape=(80, 160, 3)))\n",
    "# model.add(Convolution2D(36, 5, 5))\n",
    "# model.add(Convolution2D(48, 5, 5))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# # model.add(Convolution2D(48, 5, 5))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Convolution2D(64, 3, 3))\n",
    "# # model.add(Convolution2D(64, 3, 3))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# # model.add(Convolution2D(128, 3, 3))\n",
    "# # model.add(Convolution2D(128, 3, 3))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1164))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(100))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(50))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(10))\n",
    "# # model.add(Dense(len(classes)))\n",
    "# # model.add(Activation('relu'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# # model.add(Dense(1164))\n",
    "# # # model.add(Dense(100))\n",
    "# # # model.add(Dense(50))\n",
    "# # # model.add(Dense(10))\n",
    "\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(100))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(50))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# comman ai way\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "# ch, row, col = 3, 160, 320  # camera format\n",
    "ch, row, col = 3, 64, 64  # camera format\n",
    "model = Sequential()\n",
    "# # model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "# #           input_shape=(ch, row, col),\n",
    "# #           output_shape=(ch, row, col)))\n",
    "model.add(Convolution2D(16, 8, 8, input_shape=(64, 64, 3)))\n",
    "model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "model.add(ELU())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3,input_shape=(64, 64, 3)))\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(Convolution2D(128, 3, 3))\n",
    "# model.add(Convolution2D(128, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(1))\n",
    "# # model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = 1\n",
    "pr_threashold = 1\n",
    "batch_size = 256\n",
    "\n",
    "def generate_train_from_PD_batch(data,batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, new_size_row, new_size_col, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(len(data))\n",
    "            line_data = data.iloc[[i_line]].reset_index()\n",
    "            keep_pr = 0\n",
    "            x,y = preprocess_image_file_train(line_data)\n",
    "#             while keep_pr == 0:\n",
    "#                 x,y = preprocess_image_file_train(line_data)\n",
    "#                 pr_unif = np.random\n",
    "#                 if abs(y)<.1:\n",
    "#                     pr_val = np.random.uniform()\n",
    "#                     if pr_val>pr_threshold:\n",
    "#                         keep_pr = 1\n",
    "#                 else:\n",
    "#                     keep_pr = 1\n",
    "            \n",
    "            x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "            y = np.array([[y]])\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # TODO: Re-construct the network and add a pooling layer after the convolutional layer.\n",
    "# model = Sequential()\n",
    "# # model.add(Convolution2D(32, 2, 2, input_shape=(32, 32, 3)))\n",
    "# # model.add(Reshape(input_shape + (1, ), input_shape=input_shape))\n",
    "\n",
    "# # model.add(Convolution2D(32, 3,3, input_shape=(160, 320, 3)))\n",
    "# model.add(Convolution2D(32, 3, 3,input_shape=(64, 64, 3)))\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(Convolution2D(128, 3, 3))\n",
    "# model.add(Convolution2D(128, 3, 3))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "\n",
    "# # model.add(Dense(len(classes)))\n",
    "# # model.add(Activation('relu'))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# # model.add(Dense(1164))\n",
    "# # # model.add(Dense(100))\n",
    "# # # model.add(Dense(50))\n",
    "# # # model.add(Dense(10))\n",
    "\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(100))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(50))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dense(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 86s - loss: 2.3559 - acc: 0.1542    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1527: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      " 3840/20000 [====>.........................] - ETA: 68s - loss: 0.1430 - acc: 0.2068"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile('adam',loss = 'mse',metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=\"model.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "for i_pr in range(8):\n",
    "#     print(df)\n",
    "    train_r_generator = generate_train_from_PD_batch(df,batch_size)\n",
    "#     gen(20, args.host, port=args.port),\n",
    "    nb_vals = np.round(len(df)/val_size)-1\n",
    "    model.fit_generator(\n",
    "        train_r_generator,\n",
    "        samples_per_epoch=20000,\n",
    "        nb_epoch=10,\n",
    "        verbose=1)\n",
    "    \n",
    "    pr_threashold = 1/(i_pr+1)*1\n",
    "\n",
    "# history = model.fit(x_data, y_data, batch_size=128, nb_epoch=2, validation_split=0.2)\n",
    "# def generate_arrays_from_file():\n",
    "#     for i in range(0,len(y_data)):\n",
    "#         yield (x_data[i],y_data[i])\n",
    "\n",
    "# # #     for i in range(0,len(df)):\n",
    "    \n",
    "\n",
    "# model.fit_generator(\n",
    "#     generate_arrays_from_file(),\n",
    "#     samples_per_epoch=10000,\n",
    "#     nb_epoch=1)\n",
    "# assert(history.history['val_acc'][-1] > 0.91), \"The validation accuracy is: %.3f.  It should be greater than 0.91\" % history.history['val_acc'][-1]\n",
    "print('Tests passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = model.to_json()\n",
    "model.save_weights(\"model.h5\", True)\n",
    "with open('model.json', 'w') as outfile :\n",
    "    json.dump(json_string, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.iloc[[0]]['steering'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
